%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Methodologie}{Methodology}}%
\label{ch:methodologie}

In deze bachelorproef wordt er een onderzoek op kwalitatieve en kwantitatieve wijze uitgevoerd. Op deze manier trachten we de volgende onderzoeksvraag te beantwoorden: "Kan GraphQL of een soortgelijke oplossing geïmplementeerd worden in een zelfontwikkelde accelerator?".

Dit gebeurt als start door het uitvoeren van een literatuurstudie die terug te vinden is in hoofdstuk 2 onder Stand van zaken. De implementatie en bjihorende uitwerkingen zijn zowel in een thuisnetwerk evenals in een bedrijfsnetwerk uitgevoerd. Hiervoor was van Delaware uit hardware en een werkomgeving voorzien met de benodigde licenties om dit te realiseren. Dit werd ondersteund door het Delaware Microsoft Integration team.

\section{\IfLanguageName{dutch}{Testomgeving}{Testomgeving}}%
\label{sec:Testomgeving}

De literatuurstudie omschrijft wat de Data-Accelerator exact is en hoe deze in hun workflow gebruikt wordt. Hierbij werden de benodigde begrippen uitgelegd om dit een vorm te geven. Dit wordt ondersteund door wetenschappelijke artikels en handleidingen opgesteld door softwareontwikkelaars. Deze werden geraadpleegd via Google Scholar en de bibliotheek van HoGent en UGent. Binnen Delaware was de code van de Data-Accelerator software en een korte demo voorzien om snel wegwijs te geraken met diens toepassingen.

Echter om deze Data-Accelerator te gebruiken moet er omgeving opgezet worden in Microsoft Azure. Aan de hand van die korte demo werd er een kant en klare omgeving opgesteld, gebruikmakend van Azure Pipelines om via YAML code deze tot een correcte werking te stellen.

Om deze pipeline uit te voeren moesten er ook BICEP bestanden aangemaakt worden, deze zijn code-gebaseerde bestanden toegepspitst op een deel van de omgeving die benodigd is zoals een databank. Deze zijn getest qua functionaliteit door Dhr. Dedeken zelf om legitimiteit toe te kennen aan de opgezette omgeving. Zodat dit onderzoek binnen de bachelorproef een beter beeld oplevert.

\section{\IfLanguageName{dutch}{verloop}{verloop}}%
\label{sec:Verloop}

Na het uitwerken van de literatuurstudie is dit onderzoek gecontinueerd met het configureren en opzetten van de benodigde services. Dit bestaat uit het documenteren van alle klassen en functies binnen de Data-Accelerator, aangezien dit nog niet aanwezig was. Op die manier kon de interne werking van de Data-Accelerator bestudeerd worden en was er controle van Dhr. Dedeken uit om mogelijke interpretatie fouten te corrigeren. Dit wordt dan ook de documenteerfase genoemd binnen het onderzoek. De documentatie werd ook geschreven aan de hand van XML bijschriften bij elke functie en klasse binnen de 53 klassen die samen de Data-Accelerator vormen.

Het volgende deel van de uitwerking was om de gehele omgeving manueel op te zetten binnen Azure met als doel een eerste blik op de werking van de Data-Accelerator te krijgen en zijn functies te testen. Hierbij werden verschillende resources binneen Azure opgezet en voorzien van benodigde data en instellingen om een werkend geheel te vormen. Dit vormt dan ook de basis om de BICEP bestanden op te stellen.

Vervolgens werden BICEP templates opgesteld die via enkele globaal gedefineerde parameters een omgeving konden opzetten. Hiervoor werden van de manuele opgezette omgeving in Azure ARM templates gegenereerd. Deze zijn dan manueel omgevormd tot BICEP templates vanwege de herbruikbaarheid in meerdere omgevingen. De keuze voor BICEP kwam er doordat als men zich bij ARM templates houdt en er loopt iets mis bij het opzetten van de omgeving, deze alle voorgaande data verwijderd. Dit is catastrofaal bij een project met klanten die hier volledig rond opgezet zijn.

Het volgende deel was het opstellen van een pipeline in YAML die via Azure Pipelines uitgevoerd kon worden. Hierin werden parameters meegegeven die personaliseerbaar gemaakt zijn om zo bij verschillende omgevingen correcte naamgeving en specificaties te hebben. In deze pipeline worden dan ook de BICEP templates gecontroleerd op syntaxfouten en indien alles correct bevonden is, uitgevoerd. Hierbij wordt er ook gebruik gemaakt van de Azure Command Line Interface om delen te voorzien. Er wordt ook een PowerShell script uitgevoerd om de benodigde databank in deze opstelling te voorzien van data. In een productieomgeving zal dit beschikbaar gesteld worden door de werkgever maar voor dit onderzoek is er één gecreëerd.

Als voorlaatste deel van dit onderzoek werd er dan gekeken hoe men GraphQL of soortgelijke functionaliteit kon toevoegen om deze software uit te breiden. Hiervoor is er ook gekeken naar mogelijke services die al reeds door Azure voorzien zijn. Stel dat dit mogelijk is, kan de reeds bestaande omgeving snel uitgebreid en ook geautomatiseerd worden via de vooropgestelde pipeline om een vlotte opzet bij projecten te garanderen.

Het onderzoek werd afgesloten met een test van de omgeving en of deze samen kon werken met de Data-Accelerator om zo een extra tool bij het Zwitsers zakmes toe te voegen. Dit wordt vervolgens verwerkt tot een gepaste conclusie binnen deze bachelorproef.

%% TODO: Hoe ben je te werk gegaan? Verdeel je onderzoek in grote fasen, en
%% licht in elke fase toe welke stappen je gevolgd hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent. Je moet kunnen aantonen dat je de best
%% mogelijke manier toegepast hebt om een antwoord te vinden op de
%% onderzoeksvraag.



